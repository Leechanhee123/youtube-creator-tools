#!/usr/bin/env python3
"""
ëŒ“ê¸€ ë¶„ì„ ë¡œì§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ YouTube ëŒ“ê¸€ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤‘ë³µ/ìœ ì‚¬ ëŒ“ê¸€ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import asyncio
import json
from src.services.youtube_downloader import YouTubeCommentDownloaderService
from src.services.comment_processor import CommentProcessor

async def test_comment_analysis():
    """ëŒ“ê¸€ ë¶„ì„ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    downloader = YouTubeCommentDownloaderService()
    processor = CommentProcessor()
    
    # í…ŒìŠ¤íŠ¸í•  YouTube ì˜ìƒ (ìœ ëª…í•œ ì˜ìƒìœ¼ë¡œ ëŒ“ê¸€ì´ ë§ì€ ê²ƒ)
    test_video_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"  # Rick Roll
    
    print("=" * 50)
    print("YouTube ëŒ“ê¸€ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # 1. ëŒ“ê¸€ ë‹¤ìš´ë¡œë“œ
        print(f"\nğŸ“¥ ëŒ“ê¸€ ë‹¤ìš´ë¡œë“œ ì¤‘: {test_video_url}")
        comments = await downloader.download_comments(
            video_url=test_video_url,
            limit=50  # 50ê°œ ëŒ“ê¸€ë§Œ í…ŒìŠ¤íŠ¸
        )
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(comments)}ê°œ ëŒ“ê¸€")
        
        if not comments:
            print("âŒ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ëŒ“ê¸€ ìƒ˜í”Œ ì¶œë ¥
        print(f"\nğŸ“ ëŒ“ê¸€ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
        for i, comment in enumerate(comments[:3]):
            print(f"  {i+1}. [{comment['author']}] {comment['text'][:50]}...")
            print(f"     ì¢‹ì•„ìš”: {comment['like_count']}, ID: {comment['comment_id']}")
        
        # 3. ì™„ì „ ì¤‘ë³µ ëŒ“ê¸€ íƒì§€
        print(f"\nğŸ” ì™„ì „ ì¤‘ë³µ ëŒ“ê¸€ íƒì§€...")
        exact_duplicates = processor.detect_exact_duplicates(comments)
        
        print(f"âœ… ë°œê²¬ëœ ì™„ì „ ì¤‘ë³µ ê·¸ë£¹: {len(exact_duplicates)}ê°œ")
        
        if exact_duplicates:
            for i, (hash_key, group) in enumerate(exact_duplicates.items()):
                print(f"\n  ê·¸ë£¹ {i+1}: {len(group)}ê°œ ì¤‘ë³µ")
                print(f"    í…ìŠ¤íŠ¸: '{group[0]['text'][:30]}...'")
                print(f"    ëŒ“ê¸€ IDë“¤: {[c['comment_id'] for c in group]}")
                print(f"    ì‘ì„±ìë“¤: {[c['author'] for c in group]}")
        
        # 4. ìœ ì‚¬ ëŒ“ê¸€ íƒì§€
        print(f"\nğŸ” ìœ ì‚¬ ëŒ“ê¸€ íƒì§€ (ì„ê³„ê°’: {processor.similarity_threshold})...")
        similar_groups = processor.detect_similar_duplicates(comments)
        
        print(f"âœ… ë°œê²¬ëœ ìœ ì‚¬ ëŒ“ê¸€ ê·¸ë£¹: {len(similar_groups)}ê°œ")
        
        if similar_groups:
            for i, group in enumerate(similar_groups):
                print(f"\n  ê·¸ë£¹ {i+1}: {len(group)}ê°œ ìœ ì‚¬")
                print(f"    ëŒ€í‘œ í…ìŠ¤íŠ¸: '{group[0]['text'][:30]}...'")
                print(f"    ëŒ“ê¸€ IDë“¤: {[c['comment_id'] for c in group]}")
                
                # ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ í‘œì‹œ
                for j, comment in enumerate(group[1:3]):  # ì²˜ìŒ 2ê°œë§Œ
                    similarity = processor.calculate_similarity(group[0]['text'], comment['text'])
                    print(f"      ìœ ì‚¬ {j+1}: '{comment['text'][:30]}...' (ìœ ì‚¬ë„: {similarity:.3f})")
        
        # 5. ìŠ¤íŒ¸ íŒ¨í„´ ë¶„ì„
        print(f"\nğŸ“Š ìŠ¤íŒ¸ íŒ¨í„´ ë¶„ì„...")
        spam_patterns = processor.analyze_spam_patterns(comments)
        
        print(f"  ì™„ì „ ì¤‘ë³µ ê·¸ë£¹: {spam_patterns['exact_duplicates']}ê°œ")
        print(f"  ìœ ì‚¬ ê·¸ë£¹: {spam_patterns['similar_groups']}ê°œ")
        print(f"  ì§§ì€ ë°˜ë³µ ëŒ“ê¸€: {spam_patterns['short_repetitive']}ê°œ")
        print(f"  ì´ëª¨ì§€ë§Œ ëŒ“ê¸€: {spam_patterns['emoji_spam']}ê°œ")
        print(f"  ë§í¬ í¬í•¨ ëŒ“ê¸€: {spam_patterns['link_spam']}ê°œ")
        
        if spam_patterns['suspicious_authors']:
            print(f"\n  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì‘ì„±ì (ìƒìœ„ 3ëª…):")
            for author_info in spam_patterns['suspicious_authors'][:3]:
                print(f"    {author_info['author']}: {author_info['count']}ê°œ ëŒ“ê¸€")
        
        # 6. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€ ID ëª©ë¡
        suspicious_ids = processor.get_suspicious_comment_ids(comments)
        print(f"\nğŸš¨ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€ ID ëª©ë¡: {len(suspicious_ids)}ê°œ")
        print(f"  {suspicious_ids[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
        
        # 7. ì „ì²´ ë¶„ì„ ê²°ê³¼
        print(f"\nğŸ“‹ ì „ì²´ ë¶„ì„ ê²°ê³¼...")
        analysis_result = processor.process_comments(comments)
        
        print(f"  ì „ì²´ ëŒ“ê¸€: {analysis_result['total_comments']}ê°œ")
        print(f"  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€: {analysis_result['suspicious_count']}ê°œ")
        print(f"  ì˜ì‹¬ ë¹„ìœ¨: {(analysis_result['suspicious_count']/analysis_result['total_comments']*100):.1f}%")
        
        # 8. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§® ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸...")
        test_texts = [
            ("ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”"),  # ë™ì¼
            ("ì¢‹ì€ ì˜ìƒì´ë„¤ìš”", "ì¢‹ì€ ì˜ìƒì…ë‹ˆë‹¤"),  # ìœ ì‚¬
            ("ì •ë§ ëŒ€ë°•ì´ë‹¤", "ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©"),  # ë‹¤ë¦„
        ]
        
        for text1, text2 in test_texts:
            similarity = processor.calculate_similarity(text1, text2)
            print(f"  '{text1}' vs '{text2}': {similarity:.3f}")
        
        print(f"\nâœ… ëŒ“ê¸€ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

async def test_with_sample_data():
    """ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "=" * 50)
    print("ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    processor = CommentProcessor()
    
    # ìƒ˜í”Œ ëŒ“ê¸€ ë°ì´í„° (ì¤‘ë³µê³¼ ìœ ì‚¬ ëŒ“ê¸€ í¬í•¨)
    sample_comments = [
        {"comment_id": "1", "text": "ì •ë§ ì¢‹ì€ ì˜ìƒì´ë„¤ìš”!", "author": "user1"},
        {"comment_id": "2", "text": "ì •ë§ ì¢‹ì€ ì˜ìƒì´ë„¤ìš”!", "author": "user2"},  # ì™„ì „ ë™ì¼
        {"comment_id": "3", "text": "ì •ë§ ì¢‹ì€ ì˜ìƒì´ë„¤ìš”!", "author": "user3"},  # ì™„ì „ ë™ì¼
        {"comment_id": "4", "text": "ì •ë§ ì¢‹ì€ ì˜ìƒì…ë‹ˆë‹¤", "author": "user4"},   # ìœ ì‚¬
        {"comment_id": "5", "text": "ì¢‹ì€ ì˜ìƒì´ë„¤ìš” ì •ë§", "author": "user5"},   # ìœ ì‚¬
        {"comment_id": "6", "text": "ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì˜ ëŒ“ê¸€", "author": "user6"},
        {"comment_id": "7", "text": "ã…‹ã…‹ã…‹", "author": "user7"},             # ì§§ì€ ëŒ“ê¸€
        {"comment_id": "8", "text": "ã…‹ã…‹ã…‹", "author": "user8"},             # ì§§ì€ ëŒ“ê¸€ ì¤‘ë³µ
        {"comment_id": "9", "text": "ğŸ˜‚ğŸ˜‚ğŸ˜‚", "author": "user9"},            # ì´ëª¨ì§€ë§Œ
        {"comment_id": "10", "text": "https://example.com ë§í¬", "author": "user10"},  # ë§í¬ í¬í•¨
    ]
    
    # ë¶„ì„ ì‹¤í–‰
    analysis_result = processor.process_comments(sample_comments)
    
    print(f"ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
    print(f"  ì „ì²´ ëŒ“ê¸€: {analysis_result['total_comments']}ê°œ")
    print(f"  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€: {analysis_result['suspicious_count']}ê°œ")
    
    # ì¤‘ë³µ ê·¸ë£¹ ìƒì„¸ ì •ë³´
    exact_groups = analysis_result['duplicate_groups']['exact_duplicates']['groups']
    print(f"\n  ì™„ì „ ì¤‘ë³µ ê·¸ë£¹: {len(exact_groups)}ê°œ")
    for i, group in enumerate(exact_groups):
        print(f"    ê·¸ë£¹ {i+1}: '{group['text_sample']}' - {group['duplicate_count']}ê°œ")
        print(f"      ID: {group['comment_ids']}")
    
    similar_groups = analysis_result['duplicate_groups']['similar_groups']['groups']
    print(f"\n  ìœ ì‚¬ ëŒ“ê¸€ ê·¸ë£¹: {len(similar_groups)}ê°œ")
    for i, group in enumerate(similar_groups):
        print(f"    ê·¸ë£¹ {i+1}: '{group['representative_text']}' - {group['similar_count']}ê°œ")
        print(f"      ID: {group['comment_ids']}")
    
    print(f"\n  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€ ID: {analysis_result['suspicious_comment_ids']}")
    
    return analysis_result

if __name__ == "__main__":
    print("ëŒ“ê¸€ ë¶„ì„ ë¡œì§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸
    asyncio.run(test_with_sample_data())
    
    # 2. ì‹¤ì œ YouTube ëŒ“ê¸€ í…ŒìŠ¤íŠ¸ (ë„¤íŠ¸ì›Œí¬ ì—°ê²° í•„ìš”)
    print(f"\nì‹¤ì œ YouTube ëŒ“ê¸€ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    response = input().strip().lower()
    
    if response == 'y':
        asyncio.run(test_comment_analysis())
    else:
        print("ì‹¤ì œ í…ŒìŠ¤íŠ¸ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
    
    print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")