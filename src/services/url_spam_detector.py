"""URL ìŠ¤íŒ¸ íƒì§€ ì„œë¹„ìŠ¤"""

import re
from typing import Dict, List, Any, Optional, Set
from urllib.parse import urlparse, parse_qs
import logging

logger = logging.getLogger(__name__)


class URLSpamDetector:
    """ëŒ“ê¸€ ë‚´ URL ë° ìŠ¤íŒ¸ íŒ¨í„´ íƒì§€"""
    
    def __init__(self):
        # ì¹´í…Œê³ ë¦¬ë³„ ì˜ì‹¬ íŒ¨í„´ ì •ì˜
        self.suspicious_patterns = {
            'adult_content': {
                'keywords': ['ì„±ì¸', '19ê¸ˆ', 'l9ê¸ˆ', 'adult', 'xxx', 'porn', 'ì•¼ë™', 'ì„±ì¸ë°©ì†¡', '19ë°©', 'ì„±ì¸ì‚¬ì´íŠ¸'],
                'domains': ['xvideos.com', 'pornhub.com', 'xnxx.com'],
                'risk_score': 10
            },
            'promotion': {
                'keywords': ['ë‚´ ì±„ë„', 'êµ¬ë…', 'ì¢‹ì•„ìš”', 'íŒ”ë¡œìš°', 'êµ¬ë…í•˜ê³ ', 'ì¢‹ì•„ìš”í•˜ê³ ', 'ë‚´ì±„ë„', 'ì œì±„ë„', 'ì²´ë„', 'ê¸°ì–µí•´ì£¼ì„¸ìš”', 'ê¼­ ê¸°ì–µ', 'ìžŠì§€ ë§ì•„'],
                'domains': ['youtube.com', 'youtu.be'],
                'risk_score': 5
            },
            'malicious': {
                'keywords': ['í´ë¦­', 'ë§í¬', 'ë°”ë¡œê°€ê¸°', 'ì ‘ì†', 'ë°©ë¬¸'],
                'domains': ['bit.ly', 'tinyurl.com', 'short.link', 'ow.ly', 'tiny.cc'],
                'risk_score': 8
            },
            'gambling': {
                'keywords': ['ì¹´ì§€ë…¸', 'ë„ë°•', 'casino', 'bet', 'ë°°íŒ…', 'í† í† ', 'ìŠ¬ë¡¯'],
                'domains': ['casino.com', 'bet365.com'],
                'risk_score': 9
            },
            'scam': {
                'keywords': ['ë¬´ë£Œ', 'ì´ë²¤íŠ¸', 'ë‹¹ì²¨', 'ê³µì§œ', 'ëˆë²Œê¸°', 'ìˆ˜ìµ', 'ìž¬íƒ', 'ë¶€ì—…'],
                'domains': [],
                'risk_score': 7
            },
            'commercial': {
                'keywords': ['íŒë§¤', 'êµ¬ë§¤', 'í• ì¸', 'íŠ¹ê°€', 'ì‡¼í•‘', 'ìƒí’ˆ', 'ì£¼ë¬¸'],
                'domains': ['shopping.naver.com', 'coupang.com', 'gmarket.co.kr'],
                'risk_score': 4
            },
            'suspicious_content': {
                'keywords': ['ë¶„ë…¸', 'í‰í™”', 'ë§ˆìŒì†', 'ì§„ì •í•œ', 'ë¶€ë“œëŸ½ê²Œ', 'ë‹¤ìŠ¤ë¦¬', 'í‰í™”ë¡œìš´', 'ì‚¶'],
                'domains': [],
                'risk_score': 3
            },
            'adult_slang': {
                'keywords': ['ìƒë‚¨ìž', 'ì„ ë¬¼ã„±ã„±', 'í•µë¶ˆë‹­ë§›', 'ê±¸..ã„¹', 'ë‚œë¦¬ë‚¬ë˜', 'ì§„ì‹¬', 'ã„¹ã…‡', 'ê°¤ì—ì„œ'],
                'domains': [],
                'risk_score': 8
            }
        }
        
        # URL ì¶”ì¶œ ì •ê·œì‹ íŒ¨í„´
        self.url_patterns = [
            # HTTP/HTTPS URL
            r'https?://(?:[-\w.])+(?:[:\d]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?',
            # www.ë„ë©”ì¸.com í˜•íƒœ
            r'www\.(?:[-\w.])+\.(?:com|kr|net|org|edu|gov|co\.kr|ne\.kr)(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?',
            # ë„ë©”ì¸.com í˜•íƒœ (ë‹¨, í•œêµ­ì–´ì™€ í˜¼ìž¬ ì‹œ)
            r'(?:^|\s)(?:[-\w.]+\.(?:com|kr|net|org|edu|gov|co\.kr|ne\.kr))(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?',
            # ìœ íŠœë¸Œ ì±„ë„ ID í˜•íƒœ
            r'(?:youtube\.com/channel/|youtube\.com/@|youtu\.be/)[\w-]+',
            # ë‹¨ì¶• URL íŒ¨í„´
            r'(?:bit\.ly|tinyurl\.com|ow\.ly|tiny\.cc)/[\w-]+',
        ]
        
        # ìœ íŠœë¸Œ ì±„ë„ íŒ¨í„´ (ë” ì •êµí•œ íƒì§€)
        self.youtube_patterns = [
            r'youtube\.com/channel/([A-Za-z0-9_-]+)',
            r'youtube\.com/@([A-Za-z0-9_ê°€-íž£-]+)',
            r'youtube\.com/c/([A-Za-z0-9_ê°€-íž£-]+)',
            r'youtube\.com/user/([A-Za-z0-9_-]+)',
            r'youtu\.be/([A-Za-z0-9_-]+)',
        ]
        
        # ë‹‰ë„¤ìž„ ì˜ì‹¬ íŒ¨í„´
        self.suspicious_nickname_patterns = [
            r'.*ì±„ë„.*',
            r'.*ì²´ë„.*',  # ì˜¤íƒ€ í¬í•¨
            r'.*êµ¬ë….*',
            r'.*tv.*',
            r'.*TV.*',
            r'.*ë°©ì†¡.*',
            r'.*ìœ íŠœë¸Œ.*',
            r'.*youtube.*',
            r'.*\.com.*',
            r'.*\.kr.*',
            r'.*www\..*',
            r'.*http.*',
            r'.*19ê¸ˆ.*',
            r'.*l9ê¸ˆ.*',  # ìˆ«ìžë¥¼ lë¡œ ëŒ€ì²´í•œ ê²½ìš°
            r'.*ì„±ì¸.*',
            r'.*adult.*',
            r'.*DOPAMIN.*',
            r'.*HIGH.*',
            r'.*PAIMIUM.*',
            r'.*NEW.*',
            r'.*ë ˆë“œ.*',
            r'.*ë‹¤í¬.*',
            r'.*_.*_.*',  # ì–¸ë”ìŠ¤ì½”ì–´ê°€ 2ê°œ ì´ìƒì¸ ê²½ìš°
            r'.*-.*-.*-.*',  # í•˜ì´í”ˆì´ 3ê°œ ì´ìƒì¸ ê²½ìš°
            r'.*í´ë¦­.*',
            r'.*ONíŒ¬.*',
            r'.*ì‚¬ê±´.*',
            r'.*l9.*ON.*',  # l9ì™€ ONì´ í•¨ê»˜ ìžˆëŠ” ê²½ìš°
        ]
    
    def extract_urls(self, text: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ URL ì¶”ì¶œ"""
        urls = []
        
        for pattern in self.url_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                url = match.group(0).strip()
                if url:
                    urls.append({
                        'url': url,
                        'start': match.start(),
                        'end': match.end(),
                        'pattern_type': 'url'
                    })
        
        return urls
    
    def extract_youtube_info(self, text: str) -> List[Dict[str, Any]]:
        """ìœ íŠœë¸Œ ì±„ë„/ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ"""
        youtube_info = []
        
        for pattern in self.youtube_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                youtube_info.append({
                    'full_match': match.group(0),
                    'identifier': match.group(1) if match.groups() else None,
                    'type': self._get_youtube_type(pattern),
                    'start': match.start(),
                    'end': match.end()
                })
        
        return youtube_info
    
    def _get_youtube_type(self, pattern: str) -> str:
        """ìœ íŠœë¸Œ íŒ¨í„´ íƒ€ìž… ê²°ì •"""
        if 'channel/' in pattern:
            return 'channel_id'
        elif '/@' in pattern:
            return 'handle'
        elif '/c/' in pattern:
            return 'custom_url'
        elif '/user/' in pattern:
            return 'username'
        elif 'youtu.be' in pattern:
            return 'video_id'
        return 'unknown'
    
    def analyze_nickname(self, nickname: str) -> Dict[str, Any]:
        """ë‹‰ë„¤ìž„ ë¶„ì„"""
        suspicion_score = 0
        detected_patterns = []
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë‹‰ë„¤ìž„ íŒ¨í„´ ì²´í¬
        for pattern in self.suspicious_nickname_patterns:
            if re.search(pattern, nickname, re.IGNORECASE):
                suspicion_score += 2
                detected_patterns.append(pattern)
        
        # URLì´ í¬í•¨ëœ ë‹‰ë„¤ìž„ ì²´í¬
        nickname_urls = self.extract_urls(nickname)
        if nickname_urls:
            suspicion_score += 5
            detected_patterns.append('contains_url')
        
        return {
            'suspicion_score': suspicion_score,
            'detected_patterns': detected_patterns,
            'contains_url': len(nickname_urls) > 0,
            'urls': nickname_urls
        }
    
    def categorize_risks(self, urls: List[Dict[str, Any]], comment_text: str, author_name: str) -> Dict[str, Any]:
        """URL ë° í…ìŠ¤íŠ¸ ìœ„í—˜ë„ ë¶„ë¥˜"""
        total_risk_score = 0
        detected_categories = []
        url_analysis = []
        
        # URL ë¶„ì„
        for url_info in urls:
            url = url_info['url']
            parsed_url = urlparse(url) if url.startswith(('http://', 'https://')) else None
            domain = parsed_url.netloc.lower() if parsed_url else url.lower()
            
            url_risk = {
                'url': url,
                'domain': domain,
                'categories': [],
                'risk_score': 0
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ ìœ„í—˜ë„ ì²´í¬
            for category, config in self.suspicious_patterns.items():
                category_risk = 0
                
                # ë„ë©”ì¸ ì²´í¬
                if any(d in domain for d in config['domains']):
                    category_risk += config['risk_score']
                    url_risk['categories'].append(category)
                
                # í‚¤ì›Œë“œ ì²´í¬ (URL ì£¼ë³€ í…ìŠ¤íŠ¸)
                text_around_url = comment_text[max(0, url_info['start']-50):url_info['end']+50]
                for keyword in config['keywords']:
                    if keyword in text_around_url.lower():
                        category_risk += config['risk_score'] * 0.5
                        if category not in url_risk['categories']:
                            url_risk['categories'].append(category)
                
                url_risk['risk_score'] += category_risk
            
            url_analysis.append(url_risk)
            total_risk_score += url_risk['risk_score']
            detected_categories.extend(url_risk['categories'])
        
        # í…ìŠ¤íŠ¸ ì „ì²´ í‚¤ì›Œë“œ ë¶„ì„
        text_risk = self._analyze_text_keywords(comment_text)
        total_risk_score += text_risk['risk_score']
        detected_categories.extend(text_risk['categories'])
        
        # ë‹‰ë„¤ìž„ ë¶„ì„
        nickname_analysis = self.analyze_nickname(author_name)
        total_risk_score += nickname_analysis['suspicion_score']
        
        return {
            'total_risk_score': total_risk_score,
            'detected_categories': list(set(detected_categories)),
            'url_analysis': url_analysis,
            'text_analysis': text_risk,
            'nickname_analysis': nickname_analysis,
            'is_suspicious': total_risk_score >= 6,  # ìž„ê³„ê°’ ì„¤ì •
            'suspicion_level': self._get_suspicion_level(total_risk_score)
        }
    
    def _analyze_text_keywords(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ë¶„ì„"""
        text_lower = text.lower()
        total_risk = 0
        detected_categories = []
        
        for category, config in self.suspicious_patterns.items():
            category_score = 0
            detected_keywords = []
            
            for keyword in config['keywords']:
                if keyword in text_lower:
                    category_score += 1
                    detected_keywords.append(keyword)
            
            if category_score > 0:
                total_risk += category_score * (config['risk_score'] * 0.3)
                detected_categories.append(category)
        
        return {
            'risk_score': total_risk,
            'categories': detected_categories
        }
    
    def _get_suspicion_level(self, risk_score: float) -> str:
        """ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •"""
        if risk_score >= 15:
            return 'high'
        elif risk_score >= 8:
            return 'medium'
        elif risk_score >= 3:
            return 'low'
        else:
            return 'safe'
    
    def _analyze_nickname_content_combination(self, nickname: str, comment_text: str) -> Dict[str, Any]:
        """ë‹‰ë„¤ìž„ê³¼ ëŒ“ê¸€ ë‚´ìš©ì˜ ì¡°í•© ë¶„ì„"""
        combination_score = 0
        detected_patterns = []
        
        # ë‹‰ë„¤ìž„ì— ì±„ë„/ì²´ë„ì´ ìžˆê³  ëŒ“ê¸€ì— í”„ë¡œëª¨ì…˜ í‚¤ì›Œë“œê°€ ìžˆëŠ” ê²½ìš°
        if re.search(r'.*ì²´?ë„.*', nickname, re.IGNORECASE):
            promotion_keywords = ['ê¸°ì–µí•´ì£¼ì„¸ìš”', 'ê¼­ ê¸°ì–µ', 'ìžŠì§€ ë§ì•„', 'ê¸°ì–µí•˜ê³ ', 'ê¼­ ìžŠì§€']
            for keyword in promotion_keywords:
                if keyword in comment_text:
                    combination_score += 8
                    detected_patterns.append(f'channel_name_with_promotion: {keyword}')
        
        # ë‹‰ë„¤ìž„ì— 19ê¸ˆ/l9ê¸ˆì´ ìžˆëŠ” ê²½ìš°
        if re.search(r'.*(19ê¸ˆ|l9ê¸ˆ).*', nickname, re.IGNORECASE):
            combination_score += 10
            detected_patterns.append('adult_content_in_nickname')
        
        # ë‹‰ë„¤ìž„ì— íŠ¹ì • í‚¤ì›Œë“œ ì¡°í•©ì´ ìžˆëŠ” ê²½ìš° (DOPAMIN, HIGH, NEW ë“±)
        suspicious_keywords = ['DOPAMIN', 'HIGH', 'NEW', 'PAIMIUM', 'ë ˆë“œ', 'ë‹¤í¬', 'í´ë¦­', 'ONíŒ¬', 'ì‚¬ê±´']
        nickname_upper = nickname.upper()
        keyword_count = sum(1 for keyword in suspicious_keywords if keyword in nickname_upper)
        if keyword_count >= 2:
            combination_score += 6
            detected_patterns.append(f'multiple_suspicious_keywords: {keyword_count}')
        
        # ë‹‰ë„¤ìž„ì— í•˜ì´í”ˆì´ 3ê°œ ì´ìƒ ìžˆëŠ” ê²½ìš° (í´ë¦­-l9-ONíŒ¬NEWì‚¬ê±´-t íŒ¨í„´)
        if len(re.findall(r'-', nickname)) >= 3:
            combination_score += 5
            detected_patterns.append('multiple_hyphens_in_nickname')
        
        # ë‹‰ë„¤ìž„ ëì— ë‹¨ì¼ ë¬¸ìžê°€ ìžˆëŠ” ê²½ìš° (ë´‡ íŒ¨í„´)
        if re.search(r'.*-[a-zA-Z]$', nickname):
            combination_score += 4
            detected_patterns.append('single_char_suffix')
        
        # ëŒ“ê¸€ì— ì„±ì¸ ìŠ¬ëž­ì´ ìžˆëŠ” ê²½ìš°
        adult_slang_keywords = ['ìƒë‚¨ìž', 'ì„ ë¬¼ã„±ã„±', 'í•µë¶ˆë‹­ë§›', 'ê±¸..ã„¹', 'ë‚œë¦¬ë‚¬ë˜']
        for slang in adult_slang_keywords:
            if slang in comment_text:
                combination_score += 6
                detected_patterns.append(f'adult_slang_detected: {slang}')
        
        # ìžìŒë§Œ ìžˆëŠ” í…ìŠ¤íŠ¸ íŒ¨í„´ (ã„±ã„±, ã„¹ã…‡ ë“±)
        consonant_pattern = re.findall(r'[ã„±-ã…Ž]{2,}', comment_text)
        if consonant_pattern:
            combination_score += 3
            detected_patterns.append(f'consonant_pattern: {consonant_pattern}')
        
        # ì´ëª¨ì§€ë¡œ ì‹œìž‘í•˜ëŠ” ìŠ¤íŒ¸ íŒ¨í„´
        if comment_text.strip().startswith('ðŸ‘ˆ'):
            combination_score += 5
            detected_patterns.append('emoji_spam_start')
        
        # ë‹‰ë„¤ìž„ê³¼ ëŒ“ê¸€ ë‚´ìš©ì´ ë„ˆë¬´ ìœ ì‚¬í•œ ê²½ìš°
        nickname_words = set(re.findall(r'\w+', nickname.lower()))
        comment_words = set(re.findall(r'\w+', comment_text.lower()))
        if len(nickname_words) > 0:
            overlap_ratio = len(nickname_words & comment_words) / len(nickname_words)
            if overlap_ratio > 0.5:
                combination_score += 4
                detected_patterns.append(f'high_nickname_comment_overlap: {overlap_ratio:.2f}')
        
        return {
            'combination_score': combination_score,
            'detected_patterns': detected_patterns
        }
    
    def analyze_comment(self, comment_text: str, author_name: str) -> Dict[str, Any]:
        """ëŒ“ê¸€ ì¢…í•© ë¶„ì„"""
        try:
            # URL ì¶”ì¶œ
            urls = self.extract_urls(comment_text)
            
            # ìœ íŠœë¸Œ ì •ë³´ ì¶”ì¶œ
            youtube_info = self.extract_youtube_info(comment_text)
            
            # ìœ„í—˜ë„ ë¶„ì„
            risk_analysis = self.categorize_risks(urls, comment_text, author_name)
            
            # ì¶”ê°€ íŒ¨í„´ ë¶„ì„
            additional_patterns = self._analyze_additional_patterns(comment_text, author_name)
            
            # ë‹‰ë„¤ìž„ê³¼ ëŒ“ê¸€ ë‚´ìš© ì¡°í•© ë¶„ì„
            combination_analysis = self._analyze_nickname_content_combination(author_name, comment_text)
            
            # ìµœì¢… ìŠ¤íŒ¸ ì ìˆ˜ ê³„ì‚°
            total_spam_score = (
                risk_analysis['total_risk_score'] + 
                additional_patterns['promotional_score'] * 2 + 
                combination_analysis['combination_score']
            )
            
            return {
                'urls': urls,
                'youtube_info': youtube_info,
                'risk_analysis': risk_analysis,
                'additional_patterns': additional_patterns,
                'combination_analysis': combination_analysis,
                'is_spam': total_spam_score >= 6 or risk_analysis['is_suspicious'] or additional_patterns['is_promotional'],
                'spam_confidence': min(100, int(total_spam_score * 4))
            }
            
        except Exception as e:
            logger.error(f"ëŒ“ê¸€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'error': str(e),
                'is_spam': False,
                'spam_confidence': 0
            }
    
    def _analyze_additional_patterns(self, comment_text: str, author_name: str) -> Dict[str, Any]:
        """ì¶”ê°€ íŒ¨í„´ ë¶„ì„"""
        patterns = {
            'repeated_chars': len(re.findall(r'(.)\1{3,}', comment_text)) > 0,  # ê°™ì€ ë¬¸ìž 4ë²ˆ ì´ìƒ ë°˜ë³µ
            'excessive_emojis': len(re.findall(r'[ðŸ˜€-ðŸ¿¿]', comment_text)) > 5,  # ì´ëª¨ì§€ 5ê°œ ì´ìƒ
            'caps_lock_heavy': len(re.findall(r'[A-Z]', comment_text)) > len(comment_text) * 0.5,  # ëŒ€ë¬¸ìž 50% ì´ìƒ
            'promotional_phrases': any(phrase in comment_text.lower() for phrase in [
                'êµ¬ë…í•˜ê³ ', 'ì¢‹ì•„ìš”í•˜ê³ ', 'íŒ”ë¡œìš°í•˜ê³ ', 'ë‚´ ì±„ë„', 'ì œ ì±„ë„'
            ]),
            'name_channel_match': any(word in author_name.lower() for word in ['ì±„ë„', 'tv', 'ë°©ì†¡']) and any(word in comment_text.lower() for word in ['êµ¬ë…', 'ì¢‹ì•„ìš”'])
        }
        
        promotional_score = sum(patterns.values())
        
        return {
            'patterns': patterns,
            'promotional_score': promotional_score,
            'is_promotional': promotional_score >= 2
        }